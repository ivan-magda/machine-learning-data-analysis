# Переобучение и недообучение

#### Недообучение

*Недообучение* — ситуация, когда алгоритм плохо описывает и обучающую выборку, и новые данные. В этом случае алгоритм необходимо усложнять.

#### Переобучение

В случае *переобучения*, данные из обучающей выборки будут описываться хорошо, а новые данные плохо. Выявить переобучение, используя только обучающую выборку, невозможно, поскольку и хорошо обученный, и переобученный алгоритмы будут хорошо ее описывать. Необходимо использовать дополнительные данные.

- Это излишняя подгонка под обучающую выборку
- Приводит к низкому качуству на новых данных
- Большие веса - признак переобученности линейных моделей

Существуют несколько подходов к выявлению переобучения:
- Отложенная выборка. Часть данных из обучающей выборки не участвуют в обучении, чтобы позже проверять на ней обученный алгоритм
- Кросс-валидация, несколько усложненный метод отложенной выборки
- Использовать меры сложности модели. Об этом пойдет речь далее

# Регуляризация

*Регуляризация* — способ борьбы с переобучением в линейных моделях.

Мерой сложности, то есть «симптомом» переобученности модели, являются большие веса при признаках.
Другая ситуация, в которой можно встретиться с переобучением — мультиколлинеарность. Так называется проблема, при которой признаки в выборке являются линейно зависимыми.

- Регуляризация вводит штраф за большие веса
- L2 - регуляризация - частый выбор
- L1 - регуляризация - сложнее оптимизировать, но можно отбирать признаки

# Коэффициент регуляризации

Введенный коэффициент λ, который стоит перед регуляризатором, называется *коэффициентом регуляризации*. Чем больше λ, тем ниже сложность модели. Например, при очень больших его значениях оптимально просто занулить все веса. В то же время при слишком низких значениях λ высок риск переобучения, то есть модель становится слишком сложной.
Поэтому нужно найти некоторое оптимальное значение λ, достаточно большое, чтобы не допустить переобучения, и не очень большое, чтобы уловить закономерности в данных. Обычно λ подбирается на кросс-валидации&

# Оценивание качества алгоритмов

Самый простой способ оценить качество алгоритма — использование отложенной выборки. В этом случае следует разбить выборку на две части: первая из двух частей будет использоваться для обучения алгоритма, а вторая, тестовая выборка, — для оценки его качества, в том числе для нахождения доли ошибок в задаче классификации, MSE (среднеквадратичной ошибки) в задаче регрессии и других мер качества в зависимости от специфики задачи.

- Для оценивания качества надо использовать данные вне обучения
- Отложенная выборка (когда выборка большая)
- Кросс-валидация (когда выборка маленькая)

# Кросс-валидация

Более системный подход — кросс валидация. В этом случае выборка делится на k блоков примерно одинакового размера. Далее по очереди каждый из этих блоков используется в качестве тестового, а все остальные — в качестве обучающей выборки.


После того, как каждый блок побывает в качестве тестового, будут получены k показателей качества. В результате усреднения получается оценка качества по кросс-валидации.


При этом встает вопрос, какое число блоков использовать. Если блоков мало, получаются надежные, но смещенные оценки. В случае большого числа блоков оценки, наоборот, получаются ненадежными (большой разброс оценок), но несмещенными.


Нет конкретных рекомендаций относительно выбора k. Обычно выбирают k = 3,5,10. Чем больше k, тем больше раз приходится обучать алгоритм. Поэтому на больших выборках следует выбирать небольшие значения k, так как даже при удалении 1/3 выборки (а она большая) оставшихся данных будет достаточно для обучения.

# Сравнение алгоритмов и выбор гиперпараметров

- Гиперпараметры - это те параметры, которые нельзя настроить по обучающей выборке
- При выборе гиперпараметров и сравнении моделей есть риск переобучения
- Надо выделять контрольную выборку

# Случайные леса

#### Композиции деревьев

Проблемы решающих деревьев:
- сильно переобучается
- сильно меняется при небольшом изменении выборки


Композиция деревьев:
- Это объединение n алгоритмов в один.
- Мы каким-то образом нашли N большое алгоритмов b1, ..., bn. Чтобы объединить их в композицию, мы усредняем их ответы, то есть суммируем ответы всех этих алгоритмов b1, ..., bn на объекте x, и делим на N большое, то есть на количество этих алгоритмов.
- Если мы решаем задачу классификации, то далее мы берем знак от этого среднего.
- Если регрессии, то просто возвращаем это среднее как ответ.
- Алгоритм a(x), который возвращает знак среднего или просто среднее и называется *композицией* n алгоритмов.
- Алгоритмы b1, ..., bn, которые мы объединяем в композицию, называются *базовыми алгоритмами*.


Итак, для того чтобы строить композицию, нужно обучить n базовых алгоритмов. При этом понятно, что нельзя их обучать на всей обучающей выборке. Они получатся одинаковыми, и в их усреднении не будет никакого смысла. Нужно делать их немного различными. Например, с помощью **рандомизации**, то есть обучать их по разным подвыборкам обучающей выборки.


Поскольку решающие деревья очень сильно меняются даже при небольших изменениях обучающей выборки, такая рандомизация с помощью подвыборок будет очень хорошо влиять на их различность. 


Подходы к рандомизации:
- [Бутстрэп](https://habrahabr.ru/company/ods/blog/324402/#butstrep)
- Генерация случайного подмножества обучающей выборки

#### Смещение и разброс
- **Смещение** показывает, насколько сильно отклоняется средний прогноз по всем обученным моделям от прогноза идеальной модели. По сути, смещение говорит, насколько мы можем аппроксимировать идеальную модель, насколько наше семейство алгоритмов сложное и позволяет восстанавливать сложные закономерности.
- **Разброс** - дисперсия ответов наших моделей. Чем больше эта дисперсия, чем выше разброс, тем сильней алгоритм зависит от небольших изменений обучающей выборки. Например, решающие деревья обладают этим свойством. Если чуть-чуть поменять обучающую выборку, дерево меняется очень сильно.


 Смещение линейных модели может быть довольно большим. Линейные модели могут восстанавливать только линейные зависимости, но при этом в большинстве задач зависимости нелинейные, из за чего смещение большое и линейная модель в принципе не может восстановить сложные зависимости. При этом разброс маленький. У линейной модели параметров столько, сколько признаков. Это очень мало. Вряд ли они сильно изменятся, если чуть-чуть поменять обучающую выборку. Итак, у **линейных моделей большое смещение и низкий разброс**.


 Решающие деревья — это полная противоположность. У них **низкое смещение**. Они могут восстанавливать очень сложные закономерности, но при этом **разброс** очень большой, поскольку деревья очень сильно меняются даже при небольших изменениях обучающей выборки. 


- Ошибка складывается из смещения и разброса
- Усреднение алгоритмов не меняет смещение и уменьшает разброс
- Чем меньше корреляция между ответами базовых алгоритмов, тем сильнее уменьшение разброса
- Бэггинг и метод случайных подпространств


Смещение характеризует, насколько сложно у нас семейство алгоритмов, насколько оно может восстанавливать сложные закономерности, а разброс говорит, насколько чувствительны алгоритмы к небольшим изменениям выборки.
При этом мы выяснили, что усреднение алгоритмов, объединение их в такую композицию не меняет смещение и при этом уменьшает разброс.
При этом чем менее коррелированы базовые алгоритмы, тем сильнее уменьшение разброса.
И обсудили два подхода к уменьшению корреляции между базовыми алгоритмами: бэггинг и метод случайных подпространств.


#### out-of-bag
- Основная идея данного подхода в том, что можно хорошо оценивать обобщающую способность случайного леса без отложенной выборки или кросс-валидации.


#### Две особенности случайного леса:
- Первая состоит в том, что он идеально параллелится. Каждое дерево строится независимо, и поэтому его можно строить на своем ядре или на своем компьютере.
- Также при обучении каждого отдельного дерева в случайном лесе используется не вся обучающая выборка, а лишь некоторое ее подмножество, а те объекты, которые не использовались при обучении, можно использовать для оценивания качества случайного леса. Этот подход называется *out-of-bag*, и он позволяет избежать использования дополнительной отложенной выборки или кросс-валидации. И при этом можно показать, что *out-of-bag* оценка очень неплохо приближает оценку, вычисленную по кросс-валидации.

# Градиентный бустинг

Итак, *случайный лес* — это композиция большого количества глубоких деревьев. При этом базовые алгоритмы (базовые решающие деревья в случайном лесе) строятся независимо друг от друга. 


**Бустинг** — это подход к построению композиций, который призван решить все эти проблемы. В бустинге базовые алгоритмы строятся последовательно, один за другим. И при этом каждый следующий выбирается так, чтобы исправлять ошибки уже построенной композиции, исправлять ошибки предыдущих базовых алгоритмов. Благодаря тому, что построение композиций в бустинге направленное, в нем достаточно простых базовых алгоритмов, например, неглубоких деревьев.

- Проблемы случайного леса могут быть в том, что строить глубокие деревья, а это очень долго и сложно, и в том, что его построение ненаправленное, каждый следующий алгоритм не зависит от предыдущих.
- Бустинг, который как раз таки является противоположностью случайного леса, он строит направленную композицию: каждый следующий алгоритм исправляет ошибки предыдущего.


Градиентный бустинг переобучается из-за того, что в нем используются довольно простые базовые алгоритмы, и вывели два способа борьбы — это *сокращение шага* и *бэггинг*, который также называется *стохастическим градиентным спуском*. 

#### Общий алгоритм градиентного бустинга

На каждой итерации мы строим новый базовый алгоритм. Для этого мы сначала вычисляем вектор сдвигов s, который показывает насколько надо изменить прогноз уже построенной композиции на каждом объекте обучающей выборки, чтобы уменьшить ошибку на этой обучающей выборке.
После того как вектор сдвигов s вычислен, мы настраиваем базовый алгоритм b n-ное так, чтобы его ответы на обучающей выборке были как можно ближе к этим сдвигам, причем близость мы измеряем с помощью квадрата отклонения.
Итак, градиентный бустинг, как правило, используется для решающих деревьев, то есть в качестве базовых алгоритмов используются решающие деревья, это наиболее популярный выбор. При этом решающие деревья выбираются не очень глубокими. Глубина обычно варьируется от двух до восьми, при этом, как правило, ближе к двум. То есть деревья очень неглубокие, и этого достаточно, чтобы восстанавливать сложные закономерности, поскольку бустинг строит направленную композицию. Чтобы он не переобучался, нужно использовать оба подхода к борьбе с переобучением, это сокращение шага и обучение каждого базового алгоритма по случайной подвыборке объектов. 


- Решающее дерево — это кусочно постоянный алгоритм, и в градиентном бустинге он настраивается на среднеквадратичную ошибку.
- Если мы перенастроим ответы в листьях этого дерева, так чтобы они были оптимальны с точки зрения исходного функционала, то мы существенно ускорим сходимость градиентного бустинга.
- Бустинг - это метод построения композиций базовых алгоритмов с помощью последовательного добавления к текущей композиции нового алгоритма с некоторым коэффициентом.
- Градиентный бустинг обучает каждый новый алгоритм так, чтобы он приближал антиградиент ошибки по ответам композиции на обучающей выборке. Аналогично минимизации функций методом градиентного спуска, в градиентном бустинге мы подправляем композицию, изменяя алгоритм в направлении антиградиента ошибки. 

# Нейронные сети

- Нейронная сеть — это универсальная модель, предназначенная для решения широкого класса задач регрессии и классификации, то есть для обучения с учителем.
- Нейрон, или однослойная нейронная сеть — это функция активации от линейной комбинации признаков объекта. При построении нейронной сети используются различные функции активации.

#### Многослойная нейронная сеть
- Сеть, которая корректно аппроксимирует текущую обучающую выборку, но плохо аппроксимирует контрольную или какую-то другую выборку той же природы, называется переобученной.
- С помощью многослойной нейронной сети можно получить аппроксимацию сколь угодно высокой точности.
- Для этого надо построить оптимальную структуру нейросети и оптимизировать ее параметры.
- Параметры оптимизируются с помощью минимизации функции ошибки.
- Существуют дифференцируемые функции ошибки для оптимизации ее параметров. 

#### Оптимизации параметров нейронной сети
- Задача оптимизации параметров — это задача минимизации функции ошибки.
- Функция ошибки зависит от выборки, от структуры нейросети, то есть числа слоев, нейронов, видов функций активации, и от значения вектора параметров.
- Для оптимизации используются как стохастические, так и градиентные методы.
- Стохастические методы требуют многократного угадывания вектора параметров и могут работать довольно долго.
- Градиентные методы требуют дифференцирования функции ошибки, но могут застревать в локальных минимумах, и поэтому выбор метода оптимизации остается прикладным искусством и, конечно же, зависит от характера решаемой задачи.

#### Регуляризация и прореживание
- Регуляризация используется для снижения переобученности сети путем загрубления ее параметров.
- Оптимальное прореживание упрощает структуру сети, удаляя лишние параметры.

# Байесовская классификация и регрессия
- Байесовский классификатор — это классификатор, принимающий решения по очень простому принципу. Он выбирает тот класс, для которого максимальна вероятность признаков при условии этого класса, домноженная на априорную вероятность этого класса.
- Чтобы обучить Байесовский классификатор, нам нужно восстановить эти вероятности.
- Оценивать вероятность признаков при условии класса как функцию многих переменных может быть довольно затруднительно. Нам может существенно не хватать данных.
- Проблема нехватки данных для восстановления многомерного распределения может решаться использованием наивного байесовского классификатора.
- В этом случае задача будет сведена к восстановлению N одномерных распределений.
- В случае бинарных признаков распределение можно восстанавливать простыми частотными оценками, и классификатор получается очень похожим на наш первый пример со спам-фильтром.


Проблема нехватки данных для восстановления распределения может решаться несколькими способами:
- Можно воспользоваться наивным байесовским классификатором и оценивать одномерные распределения.
- Можно зафиксировать класс, в котором мы будем искать наше распределение, то есть применить метод параметрического восстановления распределения.
- Можно использовать непараметрическую оценку плотности. 
