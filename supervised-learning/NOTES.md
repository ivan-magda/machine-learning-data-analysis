# Переобучение и недообучение

#### Недообучение

*Недообучение* — ситуация, когда алгоритм плохо описывает и обучающую выборку, и новые данные. В этом случае алгоритм необходимо усложнять.

#### Переобучение

В случае *переобучения*, данные из обучающей выборки будут описываться хорошо, а новые данные плохо. Выявить переобучение, используя только обучающую выборку, невозможно, поскольку и хорошо обученный, и переобученный алгоритмы будут хорошо ее описывать. Необходимо использовать дополнительные данные.

- Это излишняя подгонка под обучающую выборку
- Приводит к низкому качуству на новых данных
- Большие веса - признак переобученности линейных моделей

Существуют несколько подходов к выявлению переобучения:
- Отложенная выборка. Часть данных из обучающей выборки не участвуют в обучении, чтобы позже проверять на ней обученный алгоритм
- Кросс-валидация, несколько усложненный метод отложенной выборки
- Использовать меры сложности модели. Об этом пойдет речь далее

# Регуляризация

*Регуляризация* — способ борьбы с переобучением в линейных моделях.

Мерой сложности, то есть «симптомом» переобученности модели, являются большие веса при признаках.
Другая ситуация, в которой можно встретиться с переобучением — мультиколлинеарность. Так называется проблема, при которой признаки в выборке являются линейно зависимыми.

- Регуляризация вводит штраф за большие веса
- L2 - регуляризация - частый выбор
- L1 - регуляризация - сложнее оптимизировать, но можно отбирать признаки

# Коэффициент регуляризации

Введенный коэффициент λ, который стоит перед регуляризатором, называется *коэффициентом регуляризации*. Чем больше λ, тем ниже сложность модели. Например, при очень больших его значениях оптимально просто занулить все веса. В то же время при слишком низких значениях λ высок риск переобучения, то есть модель становится слишком сложной.
Поэтому нужно найти некоторое оптимальное значение λ, достаточно большое, чтобы не допустить переобучения, и не очень большое, чтобы уловить закономерности в данных. Обычно λ подбирается на кросс-валидации&

# Оценивание качества алгоритмов

Самый простой способ оценить качество алгоритма — использование отложенной выборки. В этом случае следует разбить выборку на две части: первая из двух частей будет использоваться для обучения алгоритма, а вторая, тестовая выборка, — для оценки его качества, в том числе для нахождения доли ошибок в задаче классификации, MSE (среднеквадратичной ошибки) в задаче регрессии и других мер качества в зависимости от специфики задачи.

- Для оценивания качества надо использовать данные вне обучения
- Отложенная выборка (когда выборка большая)
- Кросс-валидация (когда выборка маленькая)

# Кросс-валидация

Более системный подход — кросс валидация. В этом случае выборка делится на k блоков примерно одинакового размера. Далее по очереди каждый из этих блоков используется в качестве тестового, а все остальные — в качестве обучающей выборки.


После того, как каждый блок побывает в качестве тестового, будут получены k показателей качества. В результате усреднения получается оценка качества по кросс-валидации.


При этом встает вопрос, какое число блоков использовать. Если блоков мало, получаются надежные, но смещенные оценки. В случае большого числа блоков оценки, наоборот, получаются ненадежными (большой разброс оценок), но несмещенными.


Нет конкретных рекомендаций относительно выбора k. Обычно выбирают k = 3,5,10. Чем больше k, тем больше раз приходится обучать алгоритм. Поэтому на больших выборках следует выбирать небольшие значения k, так как даже при удалении 1/3 выборки (а она большая) оставшихся данных будет достаточно для обучения.

# Сравнение алгоритмов и выбор гиперпараметров

- Гиперпараметры - это те параметры, которые нельзя настроить по обучающей выборке
- При выборе гиперпараметров и сравнении моделей есть риск переобучения
- Надо выделять контрольную выборку
