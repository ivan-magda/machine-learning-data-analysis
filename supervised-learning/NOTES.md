# Переобучение

- Это излишняя подгонка под обучающую выборку
- Приводит к низкому качуству на новых данных
- Большие веса - признак переобученности линейных моделей

# Регуляризация

- Регуляризация вводит штраф за большие веса
- L2 - регуляризация - частый выбор
- L1 - регуляризация - сложнее оптимизировать, но можно отбирать признаки

# Оценивание качества алгоритмов

- Для оценивания качества надо использовать данные вне обучения
- Отложенная выборка (когда выборка большая)
- Кросс-валидация (когда выборка маленькая)

# Сравнение алгоритмов и выбор гиперпараметров

- Гиперпараметры - это те параметры, которые нельзя настроить по обучающей выборке
- При выборе гиперпараметров и сравнении моделей есть риск переобучения
- Надо выделять контрольную выборку
